{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_data length:  43500\n",
      "y_train_data length:  43500\n",
      "x_test_data length:  14500\n",
      "y_test_data length:  14500\n",
      "total dataset: 58000\n"
     ]
    }
   ],
   "source": [
    "# import the uci dataset\n",
    "\n",
    "uci_train = []\n",
    "x_train_data = []\n",
    "y_train_data = []\n",
    "uci_dir = 'uci_dataset'\n",
    "training_data_file = 'shuttle.trn'\n",
    "\n",
    "# load the training data\n",
    "with open('/'.join([os.getcwd(), uci_dir, training_data_file])) as f:\n",
    "    \n",
    "    for line in f:\n",
    "        uci.append(line) # for checking if split of data is correct\n",
    "        split = line.strip().split(' ')\n",
    "        x_values = [ float(x) for x in split[:-1]]\n",
    "        y_values = int(split[-1])\n",
    "        \n",
    "        x_train_data.append(x_values)\n",
    "        y_train_data.append([y_values])\n",
    "        \n",
    "print('x_train_data length: ', len(x_train_data))\n",
    "print('y_train_data length: ', len(y_train_data))\n",
    "# \n",
    "# print('uci[0]: %s' % uci[-1])\n",
    "# print('x_data[0]: %s' % x_data[-1])\n",
    "# print('y_data[0]: %s' % y_data[-1])\n",
    "\n",
    "np_x_data = np.array([ np.array(x) for x in x_data])\n",
    "np_y_data = np.array([ np.array(y) for y in y_data])\n",
    "\n",
    "# print('np_x_data.shape: %s' % str(np_x_data.shape))\n",
    "# print('np_y_data.shape: %s' % str(np_y_data.shape))\n",
    "\n",
    "uci_test = []\n",
    "x_test_data = []\n",
    "y_test_data = []\n",
    "test_data_file = 'shuttle.tst'\n",
    "\n",
    "# load the training data\n",
    "with open('/'.join([os.getcwd(), uci_dir, test_data_file])) as f:\n",
    "    \n",
    "    for line in f:\n",
    "        uci_test.append(line) # for checking if split of data is correct\n",
    "        split = line.strip().split(' ')\n",
    "        x_values = [ float(x) for x in split[:-1]]\n",
    "        y_values = int(split[-1])\n",
    "        \n",
    "        x_test_data.append(x_values)\n",
    "        y_test_data.append([y_values])\n",
    "        \n",
    "print('x_test_data length: ', len(x_test_data))\n",
    "print('y_test_data length: ', len(y_test_data))\n",
    "\n",
    "print('total dataset: %d' % (len(x_train_data) + len(x_test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset:\n",
      "class 1: count: 34108 ratio: 78.41%\n",
      "class 2: count: 37 ratio: 0.09%\n",
      "class 3: count: 132 ratio: 0.30%\n",
      "class 4: count: 6748 ratio: 15.51%\n",
      "class 5: count: 2458 ratio: 5.65%\n",
      "class 6: count: 6 ratio: 0.01%\n",
      "class 7: count: 11 ratio: 0.03%\n"
     ]
    }
   ],
   "source": [
    "# count the number of data for each classes - training dataset\n",
    "total_num_data = len(x_train_data)\n",
    "train_bins = [[] for _ in range(7)]\n",
    "for x, y in zip(x_train_data, y_train_data):\n",
    "    train_bins[y[0] - 1].append(x)\n",
    "    \n",
    "print('Training dataset:')\n",
    "for idx, category in enumerate(train_bins):\n",
    "    print('class %d: count: %d ratio: %.2f%%' % (idx + 1, len(category), (len(category)/float(total_num_data)) * 100) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset:\n",
      "class 1: count: 11478 ratio: 79.16%\n",
      "class 2: count: 13 ratio: 0.09%\n",
      "class 3: count: 39 ratio: 0.27%\n",
      "class 4: count: 2155 ratio: 14.86%\n",
      "class 5: count: 809 ratio: 5.58%\n",
      "class 6: count: 4 ratio: 0.03%\n",
      "class 7: count: 2 ratio: 0.01%\n"
     ]
    }
   ],
   "source": [
    "# count the number of data for each classes - training dataset\n",
    "total_num_data = len(x_test_data)\n",
    "test_bins = [[] for _ in range(7)]\n",
    "for x, y in zip(x_test_data, y_test_data):\n",
    "    test_bins[y[0] - 1].append(x)\n",
    "    \n",
    "print('Test dataset:')\n",
    "for idx, category in enumerate(test_bins):\n",
    "    print('class %d: count: %d ratio: %.2f%%' % (idx + 1, len(category), (len(category)/float(total_num_data)) * 100) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vuvuzella/Envs/machine_intelligence/lib/python3.5/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use an svm with rbf kernel function\n",
    "svm = SVC(C=0.1, kernel='rbf', gamma=1)\n",
    "svm.fit(x_train_data, y_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create predictions\n",
    "svm_predictions = svm.predict(x_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.791586\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "acc = [1 if y_pred == y_true[0] else 0 for y_pred, y_true in zip(svm_predictions, y_test_data)]\n",
    "accuracy = np.sum(acc) / float(len(acc))\n",
    "print('Accuracy: %f' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Do cross validation\n",
    "# Possible approaches\n",
    "# 1. k-fold cross validation\n",
    "# 2. Try different algorithm\n",
    "# 3. Under/Oversampling method\n",
    "# 4. Penalized Models (penalized SVM)\n",
    "# 5. Look into Anomaly Detection\n",
    "\n",
    "# Cross Validation techniques (Non-exhaustive methods)\n",
    "# 1. Holdout Method\n",
    "# 2. k-fold cross validation\n",
    "# 3. Stratified k-fold cross validation\n",
    "#    - each fold contains approximately the same \n",
    "#    percentage of samples of each target class\n",
    "#    in the case of prediction problems, the mean response value is approximately equal in all folds\n",
    "# (Exhaustive methods)\n",
    "# 4. Leave-P-Out Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6821\n",
      "class 1: 6821\n",
      "class 2: 37\n",
      "class 3: 132\n",
      "class 4: 6748\n",
      "class 5: 2458\n",
      "class 6: 6\n",
      "class 7: 11\n"
     ]
    }
   ],
   "source": [
    "# Approach 1:\n",
    "# reduce class 1's number\n",
    "half_class_one = train_bins[0][:len(train_bins[0])//5]\n",
    "print(len(half_class_one))\n",
    "hold_out_train_bin = []\n",
    "hold_out_train_bin.append(half_class_one)\n",
    "for bin_class in train_bins[1:]:\n",
    "    hold_out_train_bin.append(bin_class)\n",
    "\n",
    "for idx, bin_class in enumerate(hold_out_train_bin):\n",
    "    print('class %d: %d' % (idx + 1, len(bin_class)))\n",
    "    \n",
    "holdout_x_train = []\n",
    "holdout_y_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_holdout = SVC(C=1, kernel='rbf')\n",
    "svm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
